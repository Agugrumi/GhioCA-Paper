\section{Background}

Machine learning is the field of artificial intelligence responsible for learning from data without being explicitly programmed to do so. In this way, the results provided by the algorithm do not depend on how data is processed, but on data itselves. Obviously, it is not possible to define a single algorithm for all possible learning problems.

There are mainly two methods to train an algorithm on a dataset: \textit{supervised} and \textit{unsupervised} learning. In supervised learning, we provide a label to specify which value is associated to each entry in the dataset. Consequently, we are able to train the algorithm based on examples. In unsupervised learning, there is no label for each entry. Thus, to determinate if two examples are referring to the same result, we need a \textit{similarity measure} (e.g. if we represent data using vector, one possible measure of similarity is cross product).

\textit{Pattern Matching} is the branch of machine learning responsible for detecting pattern and regularities in data. Tipically, it is implemented through supervised learning: the dataset is composed by examples with an associated label. In this way, the algorithm learns which are the features of a specific pattern (described by the label).

One of the most used method in machine learning for image classification is \textit{deep learning}: it uses an Artificial Neural Network (or ANN), which is a Neural Network (NN) composed by more than one hidden layer, in order to classify an image, based on similarity measures (unsupervised) or training examples (supervised). Tipically, NNs use a \textit{backpropagation} algorithm, composed of two phases: \textit{feed forward} and \textit{backward propagation}. Firstly, the image is decomposed in a vector-like representation. Secondly, during feed forward phase, the vector is fed as input to the NN and it is computed. Finally, during back propagation, the result of feed forward phase is compared to the real label; in case of mismatch, the wrong parts are back propagated into the NN in order to compensate the wrong behaviour. This process is repeated for each entry in the dataset.
\todo{image of NN}
Deep Neural Networks (DNNs) can use the same principles of NNs, which implement backpropagation, but decompose data on many levels (thus "deep" network). This method is based on the assumption that data can be \textit{abstracted} or \textit{composed} in many levels, simplifing the task of comparing pieces of data.
Usually, for \textit{computer vision} tasks (e.g. \cite{Handwritten}) \textit{Convolutional Neural Networks} (CNNs) are used\cite{CNN}.
However, this algorithms do not have perfect performances: in some cases, the label assigned to an image may be wrong. As a tradeoff between reliability and usability, classifiers usually assign a \textit{probability} to a certian label. In this way, who uses the algorithm can decide a confidence interval to keep/discard classifications.

\section{Related work}

Computer Vision is a branch of machine learning which is rapidly increasing, finding a fertile ground in many applications. One of the most obvious is \textit{image processing}, which involves applying changes to an image using an algorithm. In~\cite{Rain}, researchers developed a DNN used to remove rain drops from images. As in this case, many other changes can be applied to images: increasing size with minimum quality loss, removing objects, improving image resolution, and so on. However, computer vision contains also another kind of application: \textit{image detection}. Using NNs, algorithms are able to detect pedestrians in images\cite{Pedestrian} (which is fundamental for self-driving cars) and also detect anomalous behaviours in crowds\cite{Crowd}. Being able to detect shapes (e.g. a person) and irregular patterns can also help in terrorism detection and prevention.

On the other hand, image classification has two main problems: \textit{time} and \textit{cost}. This task can be performed by a machine but, in order to do so, the algorithm needs to be previously trained with a supervised learning approach. Thus, someone has to label different images. This task is tipically done by people who are paid to execute it. Differently from machines, humans are far from fast to do image labelling; consequently, in order to obtain a large dataset, a lot of time is required.
As in other cases in Computer Science, \textit{parallelization} can improve the performance of this job: if a person needs two seconds to label an image, one thousand people can provide one thousand labelled images in the same amount of time. One good implementation of this principle is the database ImageNet\cite{ImageNet2}, ``a large-scale ontology of images built upon the backbone of the WordNet structure"\cite{ImageNet1}. This database can be used as benchmark and improvement tool for computer vision algorithms.

However, in our opinion even this last example lacks of two fundamental property: \textit{usability} and \textit{zero-day learning}. Obviously, accessing to such database in order to retrieve information and perform pattern recognition is not a task which can be performed by a common user (i.e. a person who does not have any skill in computer science) without a proper user interface. Furthermore, this database needs to be populated in the first place; this task requires paying people to do so.

Our application aims to solve this big issues, providing a usable interface for image recognition and exploiting smartphones to build a database from nothing.\todo{?}


